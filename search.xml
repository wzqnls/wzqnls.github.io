<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[jenkins解决构建完成后自动杀掉衍生进程]]></title>
    <url>%2F2017%2F09%2F28%2Fjenkins%E8%A7%A3%E5%86%B3%E6%9E%84%E5%BB%BA%E5%AE%8C%E6%88%90%E5%90%8E%E8%87%AA%E5%8A%A8%E6%9D%80%E6%8E%89%E8%A1%8D%E7%94%9F%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[java启动war包解决方式12# 添加启动参数 -Dhudson.util.ProcessTree.disable=truejava -Dhudson.util.ProcessTree.disable=true -jar jenkins.war 修改BUILD_ID 原理：jenkins默认会在构建完成后杀掉构建过程中又jenkins中shell命令触发的衍生进程。jenkins根据BUILD_ID识别某个进程是否为构建过程的衍生进程，故修改BUILD_ID后，jenkins就无法识别是否为衍生进程，则此进程能在后台保留运行 1.在execute shell中加入BUILD_ID=DONTKILLME DONTKILLME仅仅为增加可读性，则任意修改其他 在想保留的进程启动命令前加入这一行 123# 举例如下BUILD_ID=DONTKILLMEsh /home/bob/restart.sh 2.临时改变BUILD_ID值12345678OLD_BUILD_ID=$BUILD_IDecho $OLD_BUILD_IDBUILD_ID=dontKillMe#此处放入shell脚本或者shell命令BUILD_ID=$OLD_BUILD_IDecho $BUILD_ID]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以root用户运行jenkins中shell命令]]></title>
    <url>%2F2017%2F09%2F28%2F%E4%BB%A5root%E7%94%A8%E6%88%B7%E8%BF%90%E8%A1%8Cjenkins%E4%B8%ADshell%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[以centOS系统为例，记录下修改Jenkins以root用户运行的方法。 修改Jenkins配置文件1234# 打开配置文件vim /etc/sysconfig/jenkins# 修改$JENKINS_USER，并去掉当前行注释$JENKINS_USER="root" 修改Jenkins相关文件夹用户权限123chown -R root:root /var/lib/jenkinschown -R root:root /var/cache/jenkinschown -R root:root /var/log/jenkins 重启Jenkins服务并检查运行Jenkins的用户是否已经切换为root12345# 重启Jenkins（若是其他方式安装的jenkins则重启方式略不同）service jenkins restart# 查看Jenkins进程所属用户ps -ef | grep jenkins# 若显示为root用户，则表示修改完成]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scp命令用法总结]]></title>
    <url>%2F2017%2F09%2F17%2Fscp%E5%91%BD%E4%BB%A4%E7%94%A8%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[在linux环境下做本机的文件复制，可以使用cp命令进行操作。然而，本地服务器和远程服务器要做文件的传输复制时，cp命令就显得心有余而力不足了。这时，就引出了一个新的命令：scp。在学习这个命令之后，感受到了这个命令的强大之处。下面就将scp命令的几种常用的用法总结一下，方便以后日后查阅，也为有需要的小伙伴提供一丝帮助。 命令参数在服务器上键入：1scp --help 输出：123usage: scp [-12346BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file] [-l limit] [-o ssh_option] [-P port] [-S program] [[user@]host1:]file1 ... [[user@]host2:]file2 这就是scp命令的一个命令格式，针对每个参数的详细意义可以通过 man scp命令进行查阅，这里不多做赘述。 常用命令格式 scp local_file remote_username@remote_ip:remote_folder scp local_file remote_username@remote_ip:remote_folder/remote_file scp local_file remote_ip:remote_folder scp local_file remote_ip:remote_folder/remote_file local_file:本地文件 (绝对路径或相对路径皆可) remote_username:远程服务器用户名 remote_ip:远程服务器ip remote_file：远程服务器目标文件名（绝对路径） 本地&lt;-&gt;远程复制举例：1234567891011# 从本地复制到远程scp test.txt jack@192.168.1.198:/home/jack/testscp test.txt jack@192.168.1.198:/home/jack/test/test.txtscp test.txt 192.168.1.198:/home/jack/testscp test.txt 192.168.1.198:/home/jack/test/test.txt# 从远程复制到本地(仅仅是路径参数调换下位置)scp jack@192.168.1.198:/home/jack/test text.txtscp jack@192.168.1.198:/home/jack/test/test.txt test.txtscp 192.168.1.198:/home/jack/test test.txtscp 192.168.1.198:/home/jack/test/test.txt test.txt 1， 2方式需要继续键入服务器登录密码3， 4方式需要键入服务器用户名和密码 复制目录12# 添加参数 -r即可，大多参数的函数与cp命令中参数含义相同scp -r /test jack@192.168.1.198:/home/jack/test 修改远程服务器ssh端口在某些情况下，公司为了加强ssh通信的安全性，会对服务器的ssh默认端口22进行修改。然而，上面的命令中并没有涉及到端口的修改。下面就看看这种情况怎么处理。其实，scp早就设定了某个参数为实现自定义端口，没错就是 -P （大写的P）。1scp -P &lt;port&gt; test.txt jack@192.168.1.198:/home/jack/test 添加ssh公钥进行免密传输12345# 本地生成ssh密钥# 将公钥添加至远程主机的authorized_keys中# 1.手动复制公钥至authorized_keys中# 2.直接将本地公钥复制到远程服务器相应目录下的authorized_keys中scp ~/.ssh/id_rsa.pub 192.168.1.198:/root/.ssh/authorized_keys]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈对测试驱动开发思想的体会]]></title>
    <url>%2F2017%2F09%2F14%2F%E8%B0%88%E8%B0%88%E5%AF%B9%E6%B5%8B%E8%AF%95%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91%E6%80%9D%E6%83%B3%E7%9A%84%E4%BD%93%E4%BC%9A%2F</url>
    <content type="text"><![CDATA[最近学习了一本书《Python Web开发：测试驱动方法》，贯穿全书的便是测试驱动开发的编程思想。有点儿兵马未动，粮草先行的兵家思想。先简单总结一下这本书带给我的收获：1.学习了测试驱动开发的一种编程思想，与传统的瀑布开发流程又很大的出入。2.学习了如何写好功能测试，如何写好单元测试。3.先通过测试，再谈重构。 好，下面简单聊聊我对这种编程思想的体会。 何为测试驱动开发维基百科中队测试驱动开发又一个比较正式的介绍：测试驱动开发（英语：Test-driven development，缩写为TDD）是一种软件开发过程中的应用方法，由极限编程中倡导，以其倡导先写测试程序，然后编码实现其功能得名。测试驱动开发始于20世纪90年代。测试驱动开发的目的是取得快速反馈并使用“illustrate the main line”方法来构建程序。 测试驱动开发是戴两顶帽子思考的开发方式：先戴上实现功能的帽子，在测试的辅助下，快速实现其功能；再戴上重构的帽子，在测试的保护下，通过去除冗余的代码，提高代码质量。测试驱动着整个开发过程：首先，驱动代码的设计和功能的实现；其后，驱动代码的再设计和重构。 按照我个人的理解：将业务需求转化为功能测试及单元测试，业务代码则为了通过测试而不断的迭代。 测试驱动开发利弊权衡（由于未实战过tdd，看法可能略显稚嫩） 通过测试驱动开发，能保证业务代码能满足需求，不断的重构，能保证系统功能的正常运行。但是对于代码质量的把控，貌似很难做到。 测试驱动开发思想其实并不难理解，流程无非也是在测试开发重构过程中不断流转，但是个人感觉在工程实践上其实难度挺大 就个人工作经验来看，目前多数企业对于项目代码质量把控很差，项目周期紧，领导总是抱着先上线，遇到bug再解决，故TDD的开发模式在很多公司，尤其是创业公司中很难推广开，由于前期测试覆盖度不够，开发急促，导致后期上线维护异常困难 TDD的开发模式也应该分业务场景而看，但具体是哪些场景合适目前没有资格谈 TDD这种方式，还是得实践。然而以目前公司的平台，基本属于不可能。不过，就算不能在公司实践TDD的开发模式，它其中最重要的核心部分–测试，会让我在今后的开发过程中更加重视这部分。]]></content>
      <categories>
        <category>编程思想</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL二进制日志格式类型详解]]></title>
    <url>%2F2017%2F07%2F13%2FMySQL%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F%E7%B1%BB%E5%9E%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[mysql很多有类型的日志，按照组件划分的话，可以分为 服务层日志 和 存储引擎层日志 ： 服务层日志：二进制日志、慢查日志、通用日志 存储引擎层日志：innodb(重做日志、回滚日志) 其中比较重要的就是服务器层的二进制日志，其中记录了所有对mysql数据库的修改事件，包括增删改查事件和对表结构的修改事件。要注意的一点是，只有成功执行了的事件才会记录在二进制日志中，未执行成功的不会保存在二进制日志中。 二进制日志的格式： 基于段的格式 binlog_format=STATEMENT 这是mysql5.7之前默认的二进制日志格式 记录的是mysql执行的sql语句 优点： 日志记录量相对较小，节约磁盘及网络I/O 缺点： 必须要记录上下文信息，保证在从服务器上执行结果和住服务器上相同 对一些非确定性函数无法进行正确复制，比如UUID(), user()等 可能造成mysql复制的主备服务器数据不一致 命令演示： 查看当前二进制日志记录格式1234567mysql&gt; show variables like &apos;binlog_format&apos;;+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW |+---------------+-------+1 row in set (0.01 sec) 修改记录格式为statement，即改为基于段的格式12mysql&gt; set session binlog_format=statement;Query OK, 0 rows affected (0.00 sec) 此时可用查看格式命令来确认一下，是否修改成功1234567mysql&gt; show variables like 'binlog_format';+---------------+-----------+| Variable_name | Value |+---------------+-----------+| binlog_format | STATEMENT |+---------------+-----------+1 row in set (0.01 sec) 查看当前二进制日志信息12345678910111213141516171819202122mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000058 | 201 || mysql-bin.000059 | 12721 || mysql-bin.000060 | 201 || mysql-bin.000061 | 201 || mysql-bin.000062 | 1069 || mysql-bin.000063 | 201 || mysql-bin.000064 | 201 || mysql-bin.000065 | 177 || mysql-bin.000066 | 201 || mysql-bin.000067 | 177 || mysql-bin.000068 | 201 || mysql-bin.000069 | 177 || mysql-bin.000070 | 177 || mysql-bin.000071 | 201 || mysql-bin.000072 | 201 || mysql-bin.000073 | 154 |+------------------+-----------+16 rows in set (0.00 sec) 刷新日志，通过这个操作会产生一个新的log文件12345678910111213141516171819202122232425mysql&gt; flush logs;Query OK, 0 rows affected (0.02 sec)mysql&gt; show binary logs;+------------------+-----------+| Log_name | File_size |+------------------+-----------+| mysql-bin.000059 | 12721 || mysql-bin.000060 | 201 || mysql-bin.000061 | 201 || mysql-bin.000062 | 1069 || mysql-bin.000063 | 201 || mysql-bin.000064 | 201 || mysql-bin.000065 | 177 || mysql-bin.000066 | 201 || mysql-bin.000067 | 177 || mysql-bin.000068 | 201 || mysql-bin.000069 | 177 || mysql-bin.000070 | 177 || mysql-bin.000071 | 201 || mysql-bin.000072 | 201 || mysql-bin.000073 | 201 || mysql-bin.000074 | 154 |+------------------+-----------+16 rows in set (0.00 sec) 现在进行一个测试操作，创建一个新的数据库及表，并插入更新一些数据。123456789101112131415mysql&gt; create database test;Query OK, 1 row affected (0.00 sec)mysql&gt; use test;Database changedmysql&gt; create table t(id int, c1 varchar(10));Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into t values(1, 'aa'),(2, 'bb');Query OK, 2 rows affected (0.02 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; update t set c1='dd' where id=1;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 这个时候可以进入存放日志的文件夹进行查看二进制日志的具体内容，不同的操作系统存放路径不同。以ubuntu为例，路径为/var/log/mysql 刚才的操作已经写入新生成的binlog文件中，使用mysqlbinlog命令打开最新的log文件，在此文件中可以清晰的查看到我们所操作过的sql语句123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# lee @ acer in /var/log/mysql [10:58:38] C:127$ mysqlbinlog mysql-bin.000074/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170713 10:40:30 server id 1 end_log_pos 123 CRC32 0x3bcc260d Start: binlog v 4, server v 5.7.18-0ubuntu0.16.04.1-log created 170713 10:40:30# Warning: this binlog is either in use or was not closed properly.BINLOG 'nt1mWQ8BAAAAdwAAAHsAAAABAAQANS43LjE4LTB1YnVudHUwLjE2LjA0LjEtbG9nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAQ0mzDs='/*!*/;# at 123#170713 10:40:30 server id 1 end_log_pos 154 CRC32 0x004e07fa Previous-GTIDs# [empty]# at 154#170713 10:42:47 server id 1 end_log_pos 219 CRC32 0x6d2f1e61 Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 219#170713 10:42:47 server id 1 end_log_pos 313 CRC32 0x182062d1 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499913767/*!*/;SET @@session.pseudo_thread_id=8/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=33/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;create database test/*!*/;# at 313#170713 10:43:14 server id 1 end_log_pos 378 CRC32 0x5af42684 Anonymous_GTID last_committed=1 sequence_number=2SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 378#170713 10:43:14 server id 1 end_log_pos 490 CRC32 0x926e1454 Query thread_id=8 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1499913794/*!*/;create table t(id int, c1 varchar(10))/*!*/;# at 490#170713 10:43:37 server id 1 end_log_pos 555 CRC32 0x571dd95f Anonymous_GTID last_committed=2 sequence_number=3SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 555#170713 10:43:37 server id 1 end_log_pos 634 CRC32 0xea457c9c Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499913817/*!*/;BEGIN/*!*/;# at 634#170713 10:43:37 server id 1 end_log_pos 747 CRC32 0x84b084e8 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499913817/*!*/;insert into t values(1, 'aa'),(2, 'bb')/*!*/;# at 747#170713 10:43:37 server id 1 end_log_pos 778 CRC32 0xb4d17852 Xid = 25COMMIT/*!*/;# at 778#170713 10:45:32 server id 1 end_log_pos 843 CRC32 0x45fa3a6e Anonymous_GTID last_committed=3 sequence_number=4SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 843#170713 10:45:32 server id 1 end_log_pos 922 CRC32 0x8fbf2543 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499913932/*!*/;BEGIN/*!*/;# at 922#170713 10:45:32 server id 1 end_log_pos 1027 CRC32 0xd4bcab33 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499913932/*!*/;update t set c1='dd' where id=1/*!*/;# at 1027#170713 10:45:32 server id 1 end_log_pos 1058 CRC32 0x769f943d Xid = 26COMMIT/*!*/;SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 基于行的日志格式 binlog_format=ROW 这是mysql5.7之后默认的二进制日志格式 记录的是增删改查的数据行信息 优点： 使mysql主从复制更加安全 对每一行数据的修改比基于段的复制高效 由于误操作修改数据库信息，且没有备库可恢复时，可通过对日志文件数据操作反向处理恢复数据 缺点： 记录日志量较大 binlog_row_image =[FULL|MINIMAL|NOBLOB] 命令演示： 切换日志格式并刷新日志12345678910111213mysql&gt; set session binlog_format=row;Query OK, 0 rows affected (0.00 sec)mysql&gt; show variables like 'binlog_format';+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW |+---------------+-------+1 row in set (0.00 sec)mysql&gt; flush logs;Query OK, 0 rows affected (0.02 sec) 查看binlog_row_image参数默认值1234567mysql&gt; show variables like 'binlog_row_image';+------------------+-------+| Variable_name | Value |+------------------+-------+| binlog_row_image | FULL |+------------------+-------+1 row in set (0.00 sec) 为方便演示noblob参数效果，修改数据库表信息，增加一列text字段123456789101112mysql&gt; alter table t add c2 text;Query OK, 0 rows affected (0.06 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; select * from t;+------+------+------+| id | c1 | c2 |+------+------+------+| 1 | dd | NULL || 2 | bb | NULL |+------+------+------+2 rows in set (0.01 sec) 随意执行一些sql操作12345mysql&gt; insert into t values(3, 'haha', 'llala');Query OK, 1 row affected (0.01 sec)mysql&gt; delete from t where id=1;Query OK, 1 row affected (0.00 sec) 查看binlog日志123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# lee @ acer in /var/log/mysql [14:45:28] $ mysqlbinlog mysql-bin.000076/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170713 14:35:53 server id 1 end_log_pos 123 CRC32 0xbf52e415 Start: binlog v 4, server v 5.7.18-0ubuntu0.16.04.1-log created 170713 14:35:53# Warning: this binlog is either in use or was not closed properly.BINLOG 'yRRnWQ8BAAAAdwAAAHsAAAABAAQANS43LjE4LTB1YnVudHUwLjE2LjA0LjEtbG9nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAARXkUr8='/*!*/;# at 123#170713 14:35:53 server id 1 end_log_pos 154 CRC32 0xafecf53d Previous-GTIDs# [empty]# at 154#170713 14:43:03 server id 1 end_log_pos 219 CRC32 0x491b5a7e Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 219#170713 14:43:03 server id 1 end_log_pos 318 CRC32 0x4acf1cd1 Query thread_id=8 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1499928183/*!*/;SET @@session.pseudo_thread_id=8/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=33/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;alter table t add c2 text/*!*/;# at 318#170713 14:44:02 server id 1 end_log_pos 383 CRC32 0x8437eaf9 Anonymous_GTID last_committed=1 sequence_number=2SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 383#170713 14:44:02 server id 1 end_log_pos 455 CRC32 0x57adaf15 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499928242/*!*/;BEGIN/*!*/;# at 455#170713 14:44:02 server id 1 end_log_pos 504 CRC32 0xdba65133 Table_map: `test`.`t` mapped to number 498# at 504#170713 14:44:02 server id 1 end_log_pos 556 CRC32 0x19769a28 Write_rows: table id 498 flags: STMT_END_FBINLOG 'shZnWRMBAAAAMQAAAPgBAAAAAPIBAAAAAAEABHRlc3QAAXQAAwMP/AMeAAIHM1Gm2w==shZnWR4BAAAANAAAACwCAAAAAPIBAAAAAAEAAgAD//gDAAAABGhhaGEFAGxsYWxhKJp2GQ=='/*!*/;# at 556#170713 14:44:02 server id 1 end_log_pos 587 CRC32 0x6184a9a1 Xid = 47COMMIT/*!*/;# at 587#170713 14:44:16 server id 1 end_log_pos 652 CRC32 0xc585d273 Anonymous_GTID last_committed=2 sequence_number=3SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 652#170713 14:44:16 server id 1 end_log_pos 724 CRC32 0x63005380 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499928256/*!*/;BEGIN/*!*/;# at 724#170713 14:44:16 server id 1 end_log_pos 773 CRC32 0x2c52eaa1 Table_map: `test`.`t` mapped to number 498# at 773#170713 14:44:16 server id 1 end_log_pos 816 CRC32 0xa80bd454 Delete_rows: table id 498 flags: STMT_END_FBINLOG 'wBZnWRMBAAAAMQAAAAUDAAAAAPIBAAAAAAEABHRlc3QAAXQAAwMP/AMeAAIHoepSLA==wBZnWSABAAAAKwAAADADAAAAAPIBAAAAAAEAAgAD//wBAAAAAmRkVNQLqA=='/*!*/;# at 816#170713 14:44:16 server id 1 end_log_pos 847 CRC32 0x9d03bcd0 Xid = 48COMMIT/*!*/;SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 单纯的使用mysqlbinlog命令，我们无法直观的看懂日志中保存的信息，所以加参数打开12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# lee @ acer in /var/log/mysql [14:45:44] $ mysqlbinlog -vv mysql-bin.000076/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#170713 14:35:53 server id 1 end_log_pos 123 CRC32 0xbf52e415 Start: binlog v 4, server v 5.7.18-0ubuntu0.16.04.1-log created 170713 14:35:53# Warning: this binlog is either in use or was not closed properly.BINLOG 'yRRnWQ8BAAAAdwAAAHsAAAABAAQANS43LjE4LTB1YnVudHUwLjE2LjA0LjEtbG9nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAARXkUr8='/*!*/;# at 123#170713 14:35:53 server id 1 end_log_pos 154 CRC32 0xafecf53d Previous-GTIDs# [empty]# at 154#170713 14:43:03 server id 1 end_log_pos 219 CRC32 0x491b5a7e Anonymous_GTID last_committed=0 sequence_number=1SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 219#170713 14:43:03 server id 1 end_log_pos 318 CRC32 0x4acf1cd1 Query thread_id=8 exec_time=0 error_code=0use `test`/*!*/;SET TIMESTAMP=1499928183/*!*/;SET @@session.pseudo_thread_id=8/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1436549152/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\C utf8 *//*!*/;SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=33/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;alter table t add c2 text/*!*/;# at 318#170713 14:44:02 server id 1 end_log_pos 383 CRC32 0x8437eaf9 Anonymous_GTID last_committed=1 sequence_number=2SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 383#170713 14:44:02 server id 1 end_log_pos 455 CRC32 0x57adaf15 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499928242/*!*/;BEGIN/*!*/;# at 455#170713 14:44:02 server id 1 end_log_pos 504 CRC32 0xdba65133 Table_map: `test`.`t` mapped to number 498# at 504#170713 14:44:02 server id 1 end_log_pos 556 CRC32 0x19769a28 Write_rows: table id 498 flags: STMT_END_FBINLOG 'shZnWRMBAAAAMQAAAPgBAAAAAPIBAAAAAAEABHRlc3QAAXQAAwMP/AMeAAIHM1Gm2w==shZnWR4BAAAANAAAACwCAAAAAPIBAAAAAAEAAgAD//gDAAAABGhhaGEFAGxsYWxhKJp2GQ=='/*!*/;### INSERT INTO `test`.`t`### SET### @1=3 /* INT meta=0 nullable=1 is_null=0 */### @2='haha' /* VARSTRING(30) meta=30 nullable=1 is_null=0 */### @3='llala' /* BLOB/TEXT meta=2 nullable=1 is_null=0 */# at 556#170713 14:44:02 server id 1 end_log_pos 587 CRC32 0x6184a9a1 Xid = 47COMMIT/*!*/;# at 587#170713 14:44:16 server id 1 end_log_pos 652 CRC32 0xc585d273 Anonymous_GTID last_committed=2 sequence_number=3SET @@SESSION.GTID_NEXT= 'ANONYMOUS'/*!*/;# at 652#170713 14:44:16 server id 1 end_log_pos 724 CRC32 0x63005380 Query thread_id=8 exec_time=0 error_code=0SET TIMESTAMP=1499928256/*!*/;BEGIN/*!*/;# at 724#170713 14:44:16 server id 1 end_log_pos 773 CRC32 0x2c52eaa1 Table_map: `test`.`t` mapped to number 498# at 773#170713 14:44:16 server id 1 end_log_pos 816 CRC32 0xa80bd454 Delete_rows: table id 498 flags: STMT_END_FBINLOG 'wBZnWRMBAAAAMQAAAAUDAAAAAPIBAAAAAAEABHRlc3QAAXQAAwMP/AMeAAIHoepSLA==wBZnWSABAAAAKwAAADADAAAAAPIBAAAAAAEAAgAD//wBAAAAAmRkVNQLqA=='/*!*/;### DELETE FROM `test`.`t`### WHERE### @1=1 /* INT meta=0 nullable=1 is_null=0 */### @2='dd' /* VARSTRING(30) meta=30 nullable=1 is_null=0 */### @3=NULL /* BLOB/TEXT meta=2 nullable=1 is_null=1 */# at 816#170713 14:44:16 server id 1 end_log_pos 847 CRC32 0x9d03bcd0 Xid = 48COMMIT/*!*/;SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 这时，我们就可以找到我们所执行过的sql语句，同时这种格式的日志还记录了修改过的每一行数据的信息 修改binlog_row_image参数值，更新一条记录123456mysql&gt; set session binlog_row_image=minimal;Query OK, 0 rows affected (0.00 sec)mysql&gt; update t set c2='this 2' where id=2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0 查看binlog文件记录内容（只截取新增部分操作） 从记录内容可看出，日志只记录了修改那行数据的第三列，即c2的值，未变动的列并未记录123456789101112131415### UPDATE `test`.`t`### WHERE### @1=2 /* INT meta=0 nullable=1 is_null=0 */### @2='bb' /* VARSTRING(30) meta=30 nullable=1 is_null=0 */### @3=NULL /* BLOB/TEXT meta=2 nullable=1 is_null=1 */### SET### @3='this 2' /* BLOB/TEXT meta=2 nullable=1 is_null=0 */# at 1086#170713 15:18:21 server id 1 end_log_pos 1117 CRC32 0xfdd198ec Xid = 50COMMIT/*!*/;SET @@SESSION.GTID_NEXT= 'AUTOMATIC' /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 继续修改binlog_row_image参数值，更新一条记录123456mysql&gt; set session binlog_row_image=noblob;Query OK, 0 rows affected (0.00 sec)mysql&gt; update t set c1='woqu' where id=3;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0 查看binlog文件记录内容（同上） 从记录内容可以发现，日志只记录了第一列和第二列的数据，并没有记录第三列text属性的值 1234567891011### UPDATE `test`.`t`### WHERE### @1=3 /* INT meta=0 nullable=1 is_null=0 */### @2='fff' /* VARSTRING(30) meta=30 nullable=1 is_null=0 */### @3='llala' /* BLOB/TEXT meta=2 nullable=1 is_null=0 */### SET### @1=3 /* INT meta=0 nullable=1 is_null=0 */### @2='woqu' /* VARSTRING(30) meta=30 nullable=1 is_null=0 */# at 1640#170713 15:24:28 server id 1 end_log_pos 1671 CRC32 0x429c269c Xid = 55COMMIT/*!*/; 总结一下binlog_row_format三种参数的记录差异 FULL: 记录修改行的所有列数据 MINIMAL: 仅记录修改行中有发生数据变化的列 NOBOLB: 和FULL方式相似，仅仅是当blog或text这些列没有进行修改时，不会记录这些属性的列 混合日志格式 binlog_format=MIXED 特点： 根据sql语句由系统决定在基于段和基于行的日志格式中进行选择 数据量的大小由所执行的sql语句决定 总结：在选择二进制日志格式时，通常选择基于行或者混合日志格式。然而对于数据复制安全性要求高的情况下，更建议使用基于行的日志格式。另外，如果选择这种格式，务必设置binlog_row_image=minimal]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>二进制日志，binlog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[functools.lru_cache装饰器详解]]></title>
    <url>%2F2017%2F07%2F11%2Ffunctools-lru-cache%E8%A3%85%E9%A5%B0%E5%99%A8%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在functools这个模块中，有lru_cache这个一个神奇的装饰器存在。functools.lru_cache的作用主要是用来做缓存，他能把相对耗时的函数结果进行保存，避免传入相同的参数重复计算。同时，缓存并不会无限增长，不用的缓存会被释放。 举fluent python中的例子来说：首先实现一个计算运行时间的装饰器12345678910111213141516171819202122import timeimport functoolsdef clock(func): # functools.wraps(func)装饰器的作用是将func函数的相关属性复制到clock中 # 比如说__name__, __doc__等等 @functools.wraps(func) def clocked(*args, **kwargs): t0 = time.time() result = func(*args, **kwargs) elapsed = time.time() - t0 name = func.__name__ arg_lst = [] if args: arg_lst.append(', '.join(repr(arg) for arg in args)) if kwargs: pairs = ['%s=%r' % (k, w) for k, w in sorted(kwargs.items())] arg_lst.append(', '.join(pairs)) arg_str = ', '.join(arg_lst) print('[%0.8fs] %s(%s) -&gt; %r ' % (elapsed, name, arg_str, result)) return result 接下来写一个生成第n个斐波纳契数的函数12345678910from clockdeco import clock@clockdef fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1)if __name__=='__main__': print(fibonacci(6)) 运行结果：1234567891011121314151617181920212223242526[0.00000041s] fibonacci(0) -&gt; 0[0.00000051s] fibonacci(1) -&gt; 1[0.00003454s] fibonacci(2) -&gt; 1[0.00000025s] fibonacci(1) -&gt; 1[0.00000026s] fibonacci(0) -&gt; 0[0.00000024s] fibonacci(1) -&gt; 1[0.00000743s] fibonacci(2) -&gt; 1[0.00001429s] fibonacci(3) -&gt; 2[0.00005602s] fibonacci(4) -&gt; 3[0.00000022s] fibonacci(1) -&gt; 1[0.00000023s] fibonacci(0) -&gt; 0[0.00000021s] fibonacci(1) -&gt; 1[0.00000672s] fibonacci(2) -&gt; 1[0.00001346s] fibonacci(3) -&gt; 2[0.00000021s] fibonacci(0) -&gt; 0[0.00000022s] fibonacci(1) -&gt; 1[0.00000691s] fibonacci(2) -&gt; 1[0.00000022s] fibonacci(1) -&gt; 1[0.00000027s] fibonacci(0) -&gt; 0[0.00000022s] fibonacci(1) -&gt; 1[0.00000708s] fibonacci(2) -&gt; 1[0.00001363s] fibonacci(3) -&gt; 2[0.00002687s] fibonacci(4) -&gt; 3[0.00004682s] fibonacci(5) -&gt; 5[0.00011096s] fibonacci(6) -&gt; 88 有大量的重复函数计算在整个运行过程中，比如fibonacci(1)，fibonacci(2)就分别运行了多次。现在给fibonacci()函数加上@functools.lru_cache()装饰器进行缓存实现1234567891011from clockdeco import clock@functools.lru_cache()@clockdef fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1)if __name__=='__main__': print(fibonacci(6)) 一共就多了一行代码，那看看运行结果如何。12345678[0.00000041s] fibonacci(0) -&gt; 0[0.00000054s] fibonacci(1) -&gt; 1[0.00004040s] fibonacci(2) -&gt; 1[0.00000104s] fibonacci(3) -&gt; 2[0.00005465s] fibonacci(4) -&gt; 3[0.00000072s] fibonacci(5) -&gt; 5[0.00006876s] fibonacci(6) -&gt; 88 不使用lru_cache装饰器时的运行时间是0.00011096s，加上以后变成了0.00006876s。这个效率增加的杠杆的，尤其在充斥这大量重复计算时，它更能够为程序的运行节省大量的时间。 另外：functools.lru_cache(maxsize=128, typed=False)有两个可选参数，我们来看看他们分别代表的意义。 maxsize代表缓存的内存占用值，超过这个值之后，就的结果就会被释放，然后将新的计算结果进行缓存,其值应当设为2的幂 typed若为True，则会把不同的参数类型得到的结果分开保存 ps：123456@functools.lru_cache()@clockdef fibonacci(n): if n &lt; 2: return n return fibonacci(n-2) + fibonacci(n-1) 这段代码中叠加使用了两个装饰器，那具体这两个装饰器的先后顺序是怎么样的。举个例子：1234@d1@d2def f(): print('f') 等于1234def f(): print('f')f = d1(d2(f)) 也就是说从下往上依次执行]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>装饰器，functools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy架构简述]]></title>
    <url>%2F2017%2F07%2F05%2FScrapy%E6%9E%B6%E6%9E%84%E7%AE%80%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[瞅一眼官方文档给出的架构图，此图中包含了Scrapy框架的基本组件构成以及数据流的走向。 第一眼看过去，有点蒙逼是正常的，接着往下看看就会会理解了。先了解了解每个组件是做什么的： Spiders(爬虫类): Spiders是开发者自定义的一个类，用于解析相应并提取item或下个爬取的URL Scrapy Engine(引擎): Engine负责控制数据流在系统中的流动走向，并在指定条件下触发一些事件。同时，也可以简单理解为Scrapy中数据流的中转站 Scheduler(调度器): Scheduler接收Engine发出的requests，并将这些requests放入到处理队列中，以便之后Engine需要时再提供 Downloader(下载器): Downloader负责抓取网页信息并提供给Engine，进而转发至Spider Item Pipeline(处理管道): Item Pipeline负责处理Spiders类处理提取之后的item，典型的处理有数据清洗，验证以及持久化 下面需要在介绍一下架构中存在的两种中间件 Spider middlewares: Spider中间件作为Spider和Engine中间存在的特定钩子，处理Engine返回的responses和自身向Engine输出的requests、items Downloader middlewares: Downloader中间件作为Engine和Downloader中间存在的特定钩子，处理从Engine发出的requests和自身向Engine返回的responses 在后期的讲解中，会慢慢涉及中间件的开发，并利用中间件方便的完成许多功能 重点讲解一下整个架构的数据流的流通过程(看图理解)： 1. Engine从Spider获取到第一条Requests 2. Engine将这条Requests发送至Scheduler,然后从Spider准备接收下一条Requests 3. Schedulers取出队列中的一条Requests发送给Engine 4. Engine 将接收到的Requests发送至Downloader，这个过程Requests会经过Downloader Middlewares 5. 一旦页面完成下载，Downloader会成为一个Response，然后将它发送至Engine，这个发送过程也会经过Downloader Middlewares 6. Engine接收到Response后，将它发送至Spider进行处理，会经过Spider Middlewares 7. Spider处理完Response然后返回items和新的Requests至Engine，会经过Spider Middlewares 8. Engine将接收到的Item发送至Item Pipelines，然后将Requests发送至Scheduler并准备接收下一条需要爬取的Requests 9. 一次url的爬取过程结束了，然后会重复这个爬取过程，直到Schedueler中没有Requests需要处理。 通过这篇文章的阅读，可以大概了解Scrapy框架基本构成及数据流的走向。对后续Scrapy的学习会有非常大的帮助，同时为进阶的Scrapy学习及源码的剖析打下基础。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红绿灯下的思考]]></title>
    <url>%2F2017%2F06%2F10%2F%E7%BA%A2%E7%BB%BF%E7%81%AF%E4%B8%8B%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[今晚从健身房回家的时候，经过红绿灯时，正好红灯，停下了脚步。 突然意识到自己这日复一日的在人潮中涌动，在整条街中，在整个城市的灯光下，显得极为平凡，渺小。这一生，也许真的就只能是一个平凡的人，和千千万万的上班族一样为了生活奔波劳碌，来不及思考未来，来不及为真理的探索再迈近一步。 大学里所幻想未来的天马星空好像突然间没有了音讯，此时此刻想起那些曾经憧憬，看起来更像是无知的意淫。然而，理想还是要有的，万一真的实现了呢。 希望自己再今后的生活中，不被现实的压力所打倒，不被灯红酒绿所迷惑，勿忘初心，继续前行。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>思考，感悟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[byebye-csdn]]></title>
    <url>%2F2017%2F05%2F27%2Fbyebye-csdn%2F</url>
    <content type="text"><![CDATA[鉴于CSDN的广告实在是忍无可忍了，故将博客迁至此处。 原CSDN博客不再做更新，仍能访问，地址见站点概览。 最后，很高兴有了一个新的博客，新的界面，新的风格，everythind is new!ps:赠桌面一张]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>碎碎念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F05%2F25%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
